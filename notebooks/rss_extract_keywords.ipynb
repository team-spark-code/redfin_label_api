{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0397d3",
   "metadata": {},
   "source": [
    "- 기본 비교: YAKE/RAKE/TextRank/KeyBERT\n",
    "- 핵심 지표: F1@10, NDCG@10, Diversity, p95 latency(원하면 groupby 후 quantile), Jaccard variance(옵션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446857b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/workspace/redfin/redfin_label_api/notebooks\n"
     ]
    }
   ],
   "source": [
    "# pip install yake rake-nltk keybert sentence-transformers networkx langdetect scikit-learn pandas numpy python-dotenv\n",
    "from __future__ import annotations\n",
    "import os, re, json, time, random, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Callable, Optional\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from langdetect import detect\n",
    "import networkx as nx\n",
    "\n",
    "import yake\n",
    "from rake_nltk import Rake\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "load_dotenv()\n",
    "set_seed(42)\n",
    "\n",
    "print(Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CONSISTENCY_RUNS': 2,\n",
      " 'EMBED_MODEL_NAME': 'sentence-transformers/all-MiniLM-L6-v2',\n",
      " 'GOLD_JSON': 'gold_keywords.json',\n",
      " 'INPUT_JSONL': 'ai_news.jsonl',\n",
      " 'KEYBERT_DIVERSITY': 0.6,\n",
      " 'KEYBERT_NR_CANDIDATES': 20,\n",
      " 'LOG_P95_LATENCY': True,\n",
      " 'METHODS': ['yake', 'rake', 'textrank', 'keybert'],\n",
      " 'OUTPUT_REPORT_CSV': 'keyword_eval_report.csv',\n",
      " 'OUTPUT_ROWS_CSV': 'keyword_eval_rows.csv',\n",
      " 'RAKE': {'MAX_WORDS': 3},\n",
      " 'SAVE_INTERMEDIATE': True,\n",
      " 'SEED': 42,\n",
      " 'TEXTRANK': {'WINDOW': 2},\n",
      " 'TOP_K / EVAL_K': (10, 10),\n",
      " 'YAKE': {'DEDUP_LIM': 0.9, 'MAX_NGRAM': 3, 'WINDOW': 2}}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 실험 공통 설정 (CONFIG)\n",
    "# =========================\n",
    "\n",
    "# ---------- 재현성 ----------\n",
    "SEED: int = 42                  # 랜덤 시드 고정 (YAKE/RAKE에는 영향 적지만 KeyBERT 등에 일관성 부여)\n",
    "PYTHONHASHSEED: str = str(SEED) # 파이썬 해시 시드 고정 (문자열로 환경변수에 반영)\n",
    "os.environ[\"PYTHONHASHSEED\"] = PYTHONHASHSEED\n",
    "\n",
    "# ---------- 데이터 경로 ----------\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "INPUT_JSONL: str  = DATA_DIR / \"ai_news.jsonl\"             # 라인-델리미티드 JSONL 입력(각 행: {id,title,description,content,...})\n",
    "GOLD_JSON: str    = DATA_DIR / \"gold_keywords.json\"        # 골드 키워드 맵 {doc_id: [kw1, kw2, ...]} (없으면 평가 생략 가능)\n",
    "ROWS_CSV: str     = DATA_DIR / \"keyword_eval_rows.csv\"     # 문서별·알고리즘별 원시 결과 저장 경로\n",
    "REPORT_CSV: str   = DATA_DIR / \"keyword_eval_report.csv\"   # 알고리즘별 평균 리포트 저장 경로\n",
    "\n",
    "# ---------- 평가 공통 ----------\n",
    "TOP_K: int        = 10          # 각 알고리즘이 반환할 키워드 상위 K개(Precision/Recall/NDCG 대상)\n",
    "EVAL_K: int       = 10          # 평가 시 사용할 K값(보통 TOP_K와 동일하게 둠)\n",
    "CONSISTENCY_RUNS: int = 2       # 동일 입력 반복 실행 횟수(일관성/변동성 측정; 0이면 비활성)\n",
    "\n",
    "# ---------- 대상 알고리즘 선택 ----------\n",
    "# 사용 가능한 값: \"yake\", \"rake\", \"textrank\", \"keybert\"\n",
    "METHODS: list[str] = [\"yake\", \"rake\", \"textrank\", \"keybert\"]\n",
    "\n",
    "# ---------- KeyBERT/임베딩 설정 ----------\n",
    "EMBED_MODEL_NAME: str = \"sentence-transformers/all-MiniLM-L6-v2\"  # 경량·속도 균형(의미 비교용)\n",
    "KEYBERT_NR_CANDIDATES: int = 20    # 후보군 개수 (너무 크면 느려짐)\n",
    "KEYBERT_DIVERSITY: float = 0.6     # MaxSum/Maximal marginal relevance 유사 개념(높을수록 다양성↑)\n",
    "\n",
    "# ---------- YAKE 하이퍼파라미터 ----------\n",
    "YAKE_MAX_NGRAM: int = 3           # 1~3gram까지 고려\n",
    "YAKE_DEDUP_LIM: float = 0.9       # 유사 키워드 중복 제거 임계값(낮을수록 공격적 중복 제거)\n",
    "YAKE_WINDOW: int = 2              # 윈도 크기(공동 발생 고려)\n",
    "\n",
    "# ---------- RAKE 하이퍼파라미터 ----------\n",
    "RAKE_MAX_WORDS: int = 3           # n-gram 최대 단어 수(영문 RSS 기사에는 1~3 추천)\n",
    "\n",
    "# ---------- TextRank 하이퍼파라미터 ----------\n",
    "TR_WINDOW: int = 2                 # 공출현 윈도 크기(너무 크면 그래프 과밀/속도저하)\n",
    "\n",
    "# ---------- 로깅/성능 ----------\n",
    "LOG_P95_LATENCY: bool = True       # 그룹 요약 시 p95 지연 계산 포함 여부\n",
    "SAVE_INTERMEDIATE: bool = True     # 중간 산출물(행 단위 결과 CSV) 저장 여부\n",
    "\n",
    "# ---------- 운영상 권고 ----------\n",
    "#  - KeyBERT는 첫 로드 시 임베딩 모델 다운로드로 시간이 다소 소요될 수 있음.\n",
    "#  - CPU-only 환경에서도 동작하나, 데이터가 많으면 keybert 단계가 병목이 될 수 있음.\n",
    "#  - TOP_K/EVAL_K는 동일하게 두는 것을 권장(리포트 해석 단순화).\n",
    "#  - CONSISTENCY_RUNS는 2~3 수준만으로도 충분히 변동성 추세 파악 가능.\n",
    "\n",
    "def print_config():\n",
    "    \"\"\"현재 실험 설정값을 표 형태로 간단 요약 출력\"\"\"\n",
    "    from pprint import pprint\n",
    "    cfg = {\n",
    "        \"SEED\": SEED,\n",
    "        \"INPUT_JSONL\": INPUT_JSONL,\n",
    "        \"GOLD_JSON\": GOLD_JSON,\n",
    "        \"TOP_K / EVAL_K\": (TOP_K, EVAL_K),\n",
    "        \"CONSISTENCY_RUNS\": CONSISTENCY_RUNS,\n",
    "        \"METHODS\": METHODS,\n",
    "        \"EMBED_MODEL_NAME\": EMBED_MODEL_NAME,\n",
    "        \"KEYBERT_NR_CANDIDATES\": KEYBERT_NR_CANDIDATES,\n",
    "        \"KEYBERT_DIVERSITY\": KEYBERT_DIVERSITY,\n",
    "        \"YAKE\": {\"MAX_NGRAM\": YAKE_MAX_NGRAM, \"DEDUP_LIM\": YAKE_DEDUP_LIM, \"WINDOW\": YAKE_WINDOW},\n",
    "        \"RAKE\": {\"MAX_WORDS\": RAKE_MAX_WORDS},\n",
    "        \"TEXTRANK\": {\"WINDOW\": TR_WINDOW},\n",
    "        \"LOG_P95_LATENCY\": LOG_P95_LATENCY,\n",
    "        \"SAVE_INTERMEDIATE\": SAVE_INTERMEDIATE,\n",
    "        \"OUTPUT_ROWS_CSV\": ROWS_CSV,\n",
    "        \"OUTPUT_REPORT_CSV\": REPORT_CSV,\n",
    "    }\n",
    "    pprint(cfg)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8142fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 I/O 유틸 (JSONL)\n",
    "def read_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for ln in f:\n",
    "            ln = ln.strip()\n",
    "            if not ln: \n",
    "                continue\n",
    "            try:\n",
    "                out.append(json.loads(ln))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "def write_jsonl(path: str, rows: List[Dict[str, Any]]):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb84d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통일 전처리\n",
    "# pip install langdetect kiwipiepy spacy\n",
    "\n",
    "def detect_language(input_text):\n",
    "    from langdetect import detect, detect_langs\n",
    "    \n",
    "    try:\n",
    "        langs = detect(input_text) # ko\n",
    "        return langs\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] 언어 감지 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddbb7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 (영문 전제) + 토크나이즈\n",
    "_WORD_RE = re.compile(r\"[A-Za-z][A-Za-z\\-\\.]{1,29}\")\n",
    "\n",
    "def normalize_text(title: str, description: str = \"\", content: str = \"\") -> str:\n",
    "    t = f\"{(title or '').strip()} {(description or '').strip()} {(content or '').strip()}\".strip()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t\n",
    "\n",
    "def tokenize_en_simple(text: str) -> List[str]:\n",
    "    return [m.group(0).lower() for m in _WORD_RE.finditer(text)]\n",
    "\n",
    "def ngrams(tokens: List[str], n_min=1, n_max=3) -> List[str]:\n",
    "    out = []\n",
    "    for n in range(n_min, n_max + 1):\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            phrase = \" \".join(tokens[i:i+n])\n",
    "            if not re.search(r\"https?://|\\d{5,}\", phrase):\n",
    "                out.append(phrase)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25031de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee46412f5da4f8b99b2f04f71e0e906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259d816848ff413f9d34eccafc5d712d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a60d18fb89c4250804a1c0ba45fbb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2584d298713749f19a18a327f62bdeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558e734bef94da78ee4a49baf4188be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d7fcfab99441ce84c176cf3091ba0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facdbf6715854070bff5c93e6133238e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183a75decd58438d9b62722dd2c22426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a02680983304c5f9037e2a80d010454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9feff5b8f9704c4e93884d0a83ce13ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dbbd5497264cbdaaea41eb7f2c4d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 키워드 추출기 팩토리 (YAKE/RAKE/TextRank/KeyBERT)\n",
    "\n",
    "# 1. YAKE\n",
    "def make_yake(top_k: int = 10, max_ngram: int = 3, dedup_lim: float = 0.9, window: int = 2):\n",
    "    extractor = yake.KeywordExtractor(\n",
    "        lang=\"en\",\n",
    "        n=max_ngram,\n",
    "        top=top_k,\n",
    "        dedupLim=dedup_lim,\n",
    "        windowsSize=window\n",
    "    )\n",
    "    def _extract(text: str) -> List[str]:\n",
    "        return [kw for kw, _ in extractor.extract_keywords(text)]\n",
    "    return _extract\n",
    "\n",
    "# 2. RAKE\n",
    "def make_rake(top_k: int = 10, max_words: int = 3):\n",
    "    rake = Rake(min_length=1, max_length=max_words)  # 영어 불용어 내장\n",
    "    def _extract(text: str) -> List[str]:\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        phrases = [p for p, _ in rake.get_ranked_phrases_with_scores()]\n",
    "        return phrases[:top_k]\n",
    "    return _extract\n",
    "\n",
    "# 3. TextRank\n",
    "def make_textrank(top_k: int = 10, window: int = 2):\n",
    "    \"\"\"\n",
    "    경량 TextRank: 공출현 그래프 → PageRank\n",
    "    \"\"\"\n",
    "    def _extract(text: str) -> List[str]:\n",
    "        toks = tokenize_en_simple(text)\n",
    "        if not toks:\n",
    "            return []\n",
    "        words = ngrams(toks, 1, 1)\n",
    "        if not words:\n",
    "            return []\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(set(words))\n",
    "        for i in range(len(words) - window):\n",
    "            for j in range(1, window + 1):\n",
    "                a, b = words[i], words[i+j]\n",
    "                if a != b:\n",
    "                    if G.has_edge(a, b):\n",
    "                        G[a][b][\"weight\"] += 1.0\n",
    "                    else:\n",
    "                        G.add_edge(a, b, weight=1.0)\n",
    "        pr = nx.pagerank(G, alpha=0.85, weight=\"weight\")\n",
    "        ranked = sorted(pr.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [w for w, _ in ranked[:top_k]]\n",
    "    return _extract\n",
    "\n",
    "# 4. KeyBERT\n",
    "_EMBED = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "def make_keybert(top_k: int = 10, diversity: float = 0.6, nr_candidates: int = 20):\n",
    "    kb = KeyBERT(model=_EMBED)\n",
    "    def _extract(text: str) -> List[str]:\n",
    "        pairs = kb.extract_keywords(\n",
    "            text,\n",
    "            keyphrase_ngram_range=(1,3),\n",
    "            top_n=top_k,\n",
    "            use_maxsum=True,\n",
    "            nr_candidates=nr_candidates,\n",
    "            diversity=diversity,\n",
    "        )\n",
    "        return [k for k, _ in pairs]\n",
    "    return _extract\n",
    "\n",
    "EXTRACTOR_FACTORIES: Dict[str, Callable[..., Callable[[str], List[str]]]] = {\n",
    "    \"yake\": make_yake,\n",
    "    \"rake\": make_rake,\n",
    "    \"textrank\": make_textrank,\n",
    "    \"keybert\": make_keybert,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0744383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 함수\n",
    "def precision_recall_f1_at_k(pred: List[str], gold: List[str], k: int = 10) -> Tuple[float, float, float]:\n",
    "    p = set(pred[:k]); g = set(gold)\n",
    "    tp = len(p & g)\n",
    "    P = tp / max(1, len(p))\n",
    "    R = tp / max(1, len(g))\n",
    "    F1 = 2*P*R/(P+R) if (P+R) > 0 else 0.0\n",
    "    return P, R, F1\n",
    "\n",
    "def ndcg_at_k(pred: List[str], gold: List[str], k: int = 10) -> float:\n",
    "    gset = set(gold); dcg = 0.0\n",
    "    for i, w in enumerate(pred[:k], start=1):\n",
    "        rel = 1.0 if w in gset else 0.0\n",
    "        dcg += rel / math.log2(i + 1)\n",
    "    ideal = sum(1.0 / math.log2(i + 1) for i in range(1, min(k, len(gold)) + 1))\n",
    "    return dcg / max(ideal, 1e-9)\n",
    "\n",
    "def diversity_cosine(phrases: List[str]) -> float:\n",
    "    if len(phrases) < 2:\n",
    "        return 1.0\n",
    "    embs = _EMBED.encode(phrases, normalize_embeddings=True)\n",
    "    sim = cosine_similarity(embs)\n",
    "    upper = sim[np.triu_indices(len(phrases), 1)]\n",
    "    return 1.0 - float(np.mean(upper))  # 높을수록 다양"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c60de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 문서 실행/평가 + 반복 변동성(Jaccard 분산)\n",
    "def jaccard(a: List[str], b: List[str], k: int = 10) -> float:\n",
    "    A, B = set(a[:k]), set(b[:k])\n",
    "    u = len(A | B)\n",
    "    return len(A & B)/u if u else 1.0\n",
    "\n",
    "def run_extract(extractor: Callable[[str], List[str]], text: str) -> Tuple[List[str], Dict[str, Any]]:\n",
    "    t0 = time.time()\n",
    "    keys = extractor(text) if text else []\n",
    "    dt = (time.time() - t0) * 1000.0  # ms\n",
    "    return keys, {\"latency_ms\": dt, \"out_len\": len(keys)}\n",
    "\n",
    "def eval_one(pred: List[str], gold: List[str], k: int = 10) -> Dict[str, float]:\n",
    "    P, R, F1 = precision_recall_f1_at_k(pred, gold, k=k)\n",
    "    ndcg = ndcg_at_k(pred, gold, k=k)\n",
    "    div  = diversity_cosine(pred[:k])\n",
    "    return {\"P@k\": P, \"R@k\": R, \"F1@k\": F1, \"NDCG@k\": ndcg, \"Diversity\": div}\n",
    "\n",
    "def consistency_variance(extractor: Callable[[str], List[str]], text: str, runs: int = 3, k: int = 10) -> float:\n",
    "    outs = []\n",
    "    for _ in range(runs):\n",
    "        keys, _ = run_extract(extractor, text)\n",
    "        outs.append(keys)\n",
    "    if len(outs) < 2:\n",
    "        return 0.0\n",
    "    js = []\n",
    "    for i in range(len(outs)-1):\n",
    "        js.append(jaccard(outs[i], outs[i+1], k=k))\n",
    "    return float(np.var(js))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d74b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 실행 러너 (여러 알고리즘 × 데이터셋)\n",
    "def run_batch(\n",
    "    data: List[Dict[str, Any]],\n",
    "    gold_map: Dict[str, List[str]] | None,\n",
    "    methods: List[str],\n",
    "    top_k: int = 10,\n",
    "    repeat_consistency_runs: int = 0,\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    data: 각 항목에 고유 id가 존재하면 gold_map과 연결하기 좋음. (없으면 index 사용)\n",
    "    gold_map: {doc_id: [gold keywords]} 또는 None(평가 생략)\n",
    "    methods: [\"yake\",\"rake\",\"textrank\",\"keybert\"] 중 선택\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    rows = []\n",
    "    # 미리 추출기 빌드\n",
    "    exts: Dict[str, Callable[[str], List[str]]] = {}\n",
    "    for m in methods:\n",
    "        if m == \"yake\":\n",
    "            exts[m] = make_yake(top_k=top_k)\n",
    "        elif m == \"rake\":\n",
    "            exts[m] = make_rake(top_k=top_k)\n",
    "        elif m == \"textrank\":\n",
    "            exts[m] = make_textrank(top_k=top_k)\n",
    "        elif m == \"keybert\":\n",
    "            exts[m] = make_keybert(top_k=top_k)\n",
    "\n",
    "    for idx, item in enumerate(data):\n",
    "        did = item.get(\"id\", idx)\n",
    "        text = normalize_text(item.get(\"title\",\"\"), item.get(\"description\",\"\"), item.get(\"content\",\"\"))\n",
    "        for m in methods:\n",
    "            keys, info = run_extract(exts[m], text)\n",
    "            rec = {\n",
    "                \"doc_id\": did,\n",
    "                \"method\": m,\n",
    "                \"latency_ms\": info[\"latency_ms\"],\n",
    "                \"pred_kws\": keys[:top_k],\n",
    "                \"pred_len\": info[\"out_len\"],\n",
    "            }\n",
    "            # 평가\n",
    "            if gold_map and did in gold_map:\n",
    "                gold = gold_map[did]\n",
    "                met = eval_one(keys, gold, k=top_k)\n",
    "                rec.update(met)\n",
    "            # 일관성(선택)\n",
    "            if repeat_consistency_runs > 0:\n",
    "                var = consistency_variance(exts[m], text, runs=repeat_consistency_runs, k=top_k)\n",
    "                rec[\"jaccard_var\"] = var\n",
    "            rows.append(rec)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"articles.jsonl\"\n",
    "data = read_jsonl(DATA_PATH)\n",
    "\n",
    "# 골드 키워드 매핑 예시 (실험 전 사람이 만든 레이블) : {doc_id: [kw1, kw2, ...]}\n",
    "# 실제 사용 시 별도 파일에서 로딩하세요.\n",
    "gold_map = {\n",
    "    # \"123\": [\"openai\",\"gpt\",\"regulation\",\"nvidia\",\"microsoft\"],\n",
    "}\n",
    "\n",
    "methods = [\"yake\",\"rake\",\"textrank\",\"keybert\"]\n",
    "df = run_batch(\n",
    "    data=data,\n",
    "    gold_map=gold_map,              # 골드 없으면 None\n",
    "    methods=methods,\n",
    "    top_k=10,\n",
    "    repeat_consistency_runs=2,      # 일관성 측정(선택). 0이면 비활성\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 리포트\n",
    "agg_cols = [\"latency_ms\",\"P@k\",\"R@k\",\"F1@k\",\"NDCG@k\",\"Diversity\",\"jaccard_var\"]\n",
    "report = (\n",
    "    df\n",
    "    .groupby(\"method\")[agg_cols]\n",
    "    .mean()\n",
    "    .sort_values(\"F1@k\", ascending=False)\n",
    "    .round(4)\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
